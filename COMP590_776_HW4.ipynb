{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kzheng18/Comp-590-776-Assignment4-Deep-Learning/blob/main/COMP590_776_HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goBi9I04IPLY"
      },
      "source": [
        "# Homework 4. Deep learning\n",
        "\n",
        "In this homework you will play with convolutional neural networks for image classification in PyTorch: write pieces of code for training/testing routine, train a simple baseline network, design your own architecture and pick parameters to beat the baseline, fine-tune a pre-trained deep neural net, and create a simple region proposal net.\n",
        "\n",
        "The homework is graded out of 50 points:\n",
        "1. (5 points) implement testing loop and measure accuracy;\n",
        "2. (15 points) design your architecture and beat the baseline accuracy on the CIFAR-10 dataset (better accuracy -> more points);\n",
        "3. (5 points) fine-tune ResNet-50 on the Dogs-vs-Cats dataset;\n",
        "4. (5 points) use your model to create a simple region proposal net;\n",
        "5. (20 points) write a report: answer the Questions 1-8 from the problem statement in your report, and discuss your results for TODO 1-4.\n",
        "\n",
        "\n",
        "### Submission format:\n",
        "\n",
        "1. Notebook with your work (shared link or `.ipynb`)\n",
        "2. PDF report (attach just your answers to Questions 1-8 and a discussion of TODO 1-4, separately from the notebook code).\n",
        "\n",
        "You can save a copy of this notebook in Colab and just submit the link, or download the `.ipynb` notebook and submit that way. Please make sure that your link is properly shared (it's best to pick \"**everyone with the link can comment**\"), or make sure that your `.ipynb` has all your outputs (there is an option to download just the code/text-only lightweight version).\n",
        "\n",
        "Before you submit, make sure your notebook runs from start to end through **\"Runtime -> Restart and Run all\"**. If it doesn't, this likely means you executed cells out-of-order, or created variables with inconsistent names (e.g. one of the cells was using an output of a temporary variable from a cell that you deleted). Your results can also differ if you execute the training loop several times without resetting the network (making more epochs, which may result in a better result, but may also lead to overfitting)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmZ9CfUHTzB1"
      },
      "source": [
        "# Notes on using Google Colab\n",
        "\n",
        "**Important: make sure your work is saved to your Google Drive or Github before starting**\n",
        "\n",
        "`File --> Save a copy...`. See the [docs](https://www.tutorialspoint.com/google_colab/google_colab_saving_work.htm).\n",
        "\n",
        "In the top right corner you can see the available resources (RAM, Disk, etc.). Click on that button to expand the tab. By default you may get a CPU-only machine allocated. You can request an instance with a GPU through `Runtime -> Change runtime type` in the file menu bar. Public GPUs may not always be available. CPU is also sufficient for this homework, as you don't need to train the models from scratch on large datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2w1UJhN3IksQ"
      },
      "outputs": [],
      "source": [
        "# Import required packages\n",
        "import os\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.models import resnet50, ResNet50_Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZrvO4sIVX8q"
      },
      "outputs": [],
      "source": [
        "# We will use this function to put objects (networks, inputs, labels)\n",
        "# to GPU if one is available\n",
        "def to_device(obj):\n",
        "    if torch.cuda.is_available():\n",
        "        obj = obj.to(\"cuda\")\n",
        "    return obj"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LiNomoQ1xRR"
      },
      "source": [
        "# 1. CIFAR-10 image classification\n",
        "\n",
        "## 1.1 CIFAR-10 data\n",
        "\n",
        "\n",
        "The [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) is a well-known image classification dataset that contains 60,000 32x32 color images in 10 classes, with 6,000 images per class. The goal of image classification is to correctly classify each image into its corresponding class label.\n",
        "\n",
        "Achieving high accuracy on CIFAR-10 can be challenging, as the images are relatively small and contain many details, making it difficult to distinguish between some of the classes.\n",
        "\n",
        "We will create a simple convolutional neural network and train it to achieve good baseline accuracy.\n",
        "\n",
        "But first, let's look at some of the CIFAR-10 data samples. It's always beneficial to understand your data before attempting to solve the problem!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFWS7jIsIg04"
      },
      "source": [
        "Luckily, PyTorch's `torchvision` package has a native CIFAR-10 dataset implementation, so creating the dataset can be as simple as `data = torchvision.datasets.CIFAR10(root='./data', download=True)`. However, we will need a couple more things to make it handy for network training.\n",
        "\n",
        "First, define a preprocessing function that is used to transform the images in the dataset. In this case, the `ToTensor` transform is used to convert the images to PyTorch tensors, and the `Normalize` transform is used to normalize the tensor values to some range to facilitate the network convergence.\n",
        "\n",
        "Second, remember to use different datasets for training and testing. `CIFAR10` handles that through the `train` flag already, but normally you would split the dataset into two parts to test on unseen images.\n",
        "\n",
        "\n",
        "Finally, create data loaders that iterate over the train and test sets. The `batch_size` and `shuffle` arguments specify the iteration batch size and whether the data should be shuffled between epochs, and the `num_workers` argument specifies the number of subprocesses to use for data loading.\n",
        "\n",
        "## Question 1. Why is it important to use different datasets for training and testing?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abIeOmOGIF-W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dfa0610-1c2b-4e4e-eda9-5a20a9a49853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 66835038.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "preprocess = transforms.Compose(\n",
        "    [transforms.ToTensor(), # convert the data to PyTorch tensors\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # normalize the data\n",
        "\n",
        "cifar_train = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=preprocess)\n",
        "cifar_test = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=preprocess)\n",
        "\n",
        "batch_size = 32 # number of samples processed before the model is updated\n",
        "cifar_train_loader = torch.utils.data.DataLoader(\n",
        "    cifar_train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "cifar_test_loader = torch.utils.data.DataLoader(\n",
        "    cifar_test, batch_size=batch_size, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfHDv9Um6rqq"
      },
      "source": [
        "In order to show the images in the batch, we now need to un-normalize them since the original images were normalized during the dataset loading process. Let's plot the first few images from the batch and print their labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "p6uSlhZ5If2k",
        "outputId": "87ffa521-b7c0-4efe-b855-52cbd9514349"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "truck  ship horse  frog\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def show_images(img, mean, std):\n",
        "    # Un-normalize the image and plot it\n",
        "    mean = torch.tensor(mean, device=img.device)\n",
        "    std = torch.tensor(std, device=img.device)\n",
        "    img = img.permute(1, 2, 0)\n",
        "    img = img * std + mean\n",
        "    plt.imshow(img.numpy())\n",
        "\n",
        "\n",
        "# fetch a batch from the train dataset\n",
        "dataiter = iter(cifar_train_loader)\n",
        "images, labels = next(dataiter)\n",
        "nimages = min(batch_size, 4)\n",
        "norm = preprocess.transforms[-1]\n",
        "show_images(torchvision.utils.make_grid(images[:nimages]), norm.mean, norm.std)\n",
        "# print labels\n",
        "print(' '.join('%5s' % cifar_train.classes[labels[j]] for j in range(nimages)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRlkMTyz7Zbu"
      },
      "source": [
        "## 1.2 Baseline network\n",
        "\n",
        "The SimpleNet class below inherits from the nn.Module class, which is a base class for all neural network modules in PyTorch. The __init__ method initializes the various layers of the neural network, while the forward method defines the forward pass through the network. Notice that you don't have to implement the backward pass when using superpositions of standard functions and layers, since the corresponding backward pass is already implemented for these standard operations, and the backward pass for your full model is simply derived from those using the chain rule.\n",
        "\n",
        "Our network consists of two convolutional layers (conv1 and conv2) followed by two fully connected layers (fc1 and fc2), and a final output layer (fc3) with 10 output units (one for each class in the CIFAR-10 dataset). It also has a 2x down-sampling `pool` layer (applied after both conv1 and conv2), and ReLU nonlinearities between the layers.\n",
        "\n",
        "The input to the network is a batch of 32x32 color images (3 channels for RGB) and the output is a tensor of shape (batch_size, 10) representing the predicted class scores for each input image in the batch.\n",
        "\n",
        "## Question 2. Given that the input size is 32x32, and `conv1` layer is a convolution with a 5x5 kernel, what is the output size of the `conv1` layer?\n",
        "\n",
        "## Question 3. Why does `fc1` have 16 * 5 * 5 = 400 input features?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTOeB6B1IgIB"
      },
      "outputs": [],
      "source": [
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self, input_size=32, num_classes=10):\n",
        "        # define the layers of the network\n",
        "        super(SimpleNet, self).__init__()\n",
        "        # 3 input channels: RGB\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(in_features=16 * 5 * 5, out_features=120)\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
        "        # num_classes output channels\n",
        "        self.fc3 = nn.Linear(in_features=84, out_features=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Remember to use nonlinearities after hidden linear layers (conv, fc)\n",
        "        # Convolutional layers\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        # Reshape as a vector\n",
        "        x = x.view(-1, self.fc1.in_features)\n",
        "        # Fully connected (fc) layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        # Note that the output layer does not need a nonlinearity.\n",
        "        # as it models log-probability\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model_simple = SimpleNet()\n",
        "model_simple = to_device(model_simple)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkXbElno9eBn"
      },
      "source": [
        "## 1.3 Training and testing the network\n",
        "\n",
        "In order to train the network, we are still missing a couple things:\n",
        "1. A loss criterion: for most classification problems, cross-entropy is used to define loss. Luckily, we know ground truth labels for our training dataset, and our network already models log-probability output with its final fully connected layer.\n",
        "\n",
        "2. An optimizer: we will use SGD with momentum as our base optimizer. You will have to tune its parameters later, and feel free to explore other optimizers available in the `optim` package!\n",
        "\n",
        "## Question 4. As discussed in the lectures, cross-entropy is just a negative log-likelihood for the label data distribution. For M-class classification (M=10 for CIFAR-10), `label` is a random variable that takes one of M values: $target \\in {1, \\dots, M}$. What class of distributions does `label` belong to then (e.g. Gaussian, Binomial, etc.)? What are the parameters of the distribution in terms of the notations used in our formula below?\n",
        "\n",
        "$$L = -\\sum\\limits_{j=1}^M [target = j]\\log(p_j) = -\\log(p_{target})$$\n",
        "\n",
        "The training code runs over the dataset `nepoch` number of times (epochs).\n",
        "\n",
        "## TODO #1: implement the testing loop\n",
        "\n",
        "While training code is provided below, you have to implement the testing routine. It's very similar to training, even simpler, as there is no need to make a call into the optimization step! You also have to loop through the data and get network outputs. Instead of computing the loss, let's measure the accuracy of the predictions:\n",
        "$$\\text{accuracy} = \\dfrac{\\text{number_of_correct_predictions}}{\\text{total_samples}} * 100 \\%$$\n",
        "\n",
        "Use `torch.max()` to get the most likely label for every image from its per-class scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXD8IYwWTMmK"
      },
      "outputs": [],
      "source": [
        "def test(model, loader):\n",
        "    # Testing loop\n",
        "    # Make sure to set the network to the testing mode\n",
        "    # torch.no_grad() makes sure extra resources are not\n",
        "    # allocated during the network run as backward pass is not needed\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        ###################################################\n",
        "        # TODO: write your code here\n",
        "        # Return the accuracy\n",
        "        # Hint: look at the training code below for reference!\n",
        "        ###################################################\n",
        "\n",
        "        assert False, \"Implement the testing loop! Remove this assert statement.\"\n",
        "        accuracy = 0.0\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def train_and_test(model, nepochs,\n",
        "                   train_loader, test_loader,\n",
        "                   optimizer=optim.SGD,\n",
        "                   optimizer_params=None):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optimizer(model.parameters(), **optimizer_params)\n",
        "\n",
        "    for epoch in range(nepochs):\n",
        "        print(\"Epoch {}/{}\".format(epoch + 1, nepochs))\n",
        "\n",
        "        # Training loop\n",
        "        # Some networks have different behavior for training and testing,\n",
        "        # for example when BatchNorm or Dropout is used.\n",
        "        # Make sure to set the network to the training mode.\n",
        "        model.train()\n",
        "        for inputs, labels in tqdm(train_loader):\n",
        "            inputs = to_device(inputs)\n",
        "            labels = to_device(labels)\n",
        "\n",
        "            # Zero out the gradients before every iteration!\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimizer step\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        accuracy = test(model, test_loader)\n",
        "        print('Epoch {}, Test Accuracy: {:.2f}%'.format(epoch+1, accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tU5uERZHBslG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "7951f6b5-2f1b-41e9-d175-452b7fa62dfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:26<00:00, 58.47it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-41bceb8a5651>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"momentum\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m }\n\u001b[0;32m----> 5\u001b[0;31m train_and_test(model_simple, 2, cifar_train_loader, cifar_test_loader,\n\u001b[0m\u001b[1;32m      6\u001b[0m                optimizer_params=optimizer_params_default)\n",
            "\u001b[0;32m<ipython-input-6-516f3e26256e>\u001b[0m in \u001b[0;36mtrain_and_test\u001b[0;34m(model, nepochs, train_loader, test_loader, optimizer, optimizer_params)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch {}, Test Accuracy: {:.2f}%'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-516f3e26256e>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m###################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Implement the testing loop! Remove this assert statement.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Implement the testing loop! Remove this assert statement."
          ]
        }
      ],
      "source": [
        "optimizer_params_default = {\n",
        "    \"lr\": 2e-3,\n",
        "    \"momentum\": 0.9,\n",
        "}\n",
        "train_and_test(model_simple, 2, cifar_train_loader, cifar_test_loader,\n",
        "               optimizer_params=optimizer_params_default)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6ViwwK_EZek"
      },
      "source": [
        "## Question 5. What accuracy did you get with our simple network and the default settings? Is it good or bad? What is a \"bad\" accuracy for this problem (i.e. what accuracy level immediately hints at a presence of a bug in the code rather than at a need to design a better network)?\n",
        "\n",
        "\n",
        "Now let's look at some predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySgzcualTMq5"
      },
      "outputs": [],
      "source": [
        "dataiter = iter(cifar_test_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# print images\n",
        "nimages = min(batch_size, 8)\n",
        "norm = cifar_test.transform.transforms[-1]\n",
        "show_images(torchvision.utils.make_grid(images[:nimages]), norm.mean, norm.std)\n",
        "print('GroundTruth: ', ' '.join('%5s' % cifar_test.classes[labels[j]] for j in range(nimages)))\n",
        "\n",
        "###################################################\n",
        "# TODO: write your code here\n",
        "# Print out the network predictions\n",
        "###################################################\n",
        "\n",
        "assert False, \"Print out the predicted class labels.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aQR266cYojV"
      },
      "source": [
        "# 2. Design your own architecture\n",
        "\n",
        "You can start exploring the space of architectures by tuning the hyperparameters of our baseline network first. Hyperparameters are variables that are not learned from the data, but rather set before the training process begins. They affect how the model is trained and can significantly impact its performance. Those are, for example, learning rate, number of layers (depth), number of neurons per layer (width).\n",
        "\n",
        "Choosing appropriate hyperparameters is crucial for achieving good performance, and is often done through a combination of trial and error and intuition based on prior experience.\n",
        "\n",
        "\n",
        "Let's reserve a small validation set for parameter tuning out of our testing data, and test our final model on the test set, minus the validation set.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the test set into val and test_minus_val (20% and 80%, respectively)\n",
        "# Use manual seed for results repeatability.\n",
        "generator = torch.Generator().manual_seed(42)\n",
        "cifar_val, cifar_test_minus_val = random_split(cifar_test, [0.2, 0.8],\n",
        "                                               generator=generator)\n",
        "\n",
        "cifar_val_loader = torch.utils.data.DataLoader(\n",
        "    cifar_val, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "cifar_test_minus_val_loader = torch.utils.data.DataLoader(\n",
        "    cifar_test_minus_val, batch_size=batch_size, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "iUxOTwzoc4eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Question 6. Why is it important to have a validation set for parameter tuning?\n",
        "\n",
        "Try tuning your parameters, and then modify the architecture, adding layers, normalization techniques, etc. from Pytorch's `nn` package.\n",
        "\n",
        "## TODO #2: Implement a stronger network and achieve high accuracy on CIFAR-10"
      ],
      "metadata": {
        "id": "5S7vc0qvb1md"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VYcAB2PIo93"
      },
      "outputs": [],
      "source": [
        "class CustomNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        ###################################################\n",
        "        # TODO: write your code here\n",
        "        # Initialize network layers\n",
        "        ###################################################\n",
        "        raise NotImplementedError(\"Implement the initialization\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        ###################################################\n",
        "        # TODO: write your code here\n",
        "        # Implement the forward pass\n",
        "        ###################################################\n",
        "        raise NotImplementedError(\"Implement the initialization\")\n",
        "\n",
        "model_custom = CustomNet()\n",
        "model_custom = to_device(model_custom)\n",
        "optimizer_params_custom = {}\n",
        "train_and_test(model_custom, 2, cifar_train_loader, cifar_val_loader,\n",
        "               optimizer_params=optimizer_params_custom)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After you are done tuning the architecture structure and the hyperparameters, report your results with both CustomNet and SimpleNet on the `train_minus_val` split below. Discuss your resulting architecture in the report."
      ],
      "metadata": {
        "id": "HqmoAyEje61t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_simple = test(model_simple, cifar_test_minus_val_loader)\n",
        "print('Baseline model accuracy (test_minus_val): {:.2f}%'.format(accuracy_simple))\n",
        "\n",
        "accuracy_custom = test(model_custom, cifar_test_minus_val_loader)\n",
        "print('Custom model accuracy (test_minus_val): {:.2f}%'.format(accuracy_custom))"
      ],
      "metadata": {
        "id": "wXZQX0iHfI_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXLGqBU71iC-"
      },
      "source": [
        "# 3. Dogs-vs-Cats and model tuning\n",
        "\n",
        "Let's now explore some images with higher resolution than those of 32x32 from CIFAR. One of the popular classification datasets is [\"Dogs vs Cats\"](https://www.kaggle.com/c/dogs-vs-cats/data). We will use a smaller version of the dataset here, picking 2000 images subset for training. Let's download and extract the archive to the /tmp folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbxyhrwt1u6b"
      },
      "outputs": [],
      "source": [
        "# Download the dataset\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip\n",
        "\n",
        "# Unzip it to /tmp\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "# Create a PyTorch ImageFolder Dataset\n",
        "train_data = ImageFolder(\"/tmp/cats_and_dogs_filtered/train\")\n",
        "train_data[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3esN84xNlfE"
      },
      "source": [
        "Let's see how our simple (or your custom) model trained on CIFAR does on these images. For this one, mine predicted a `truck` class as a top prediction with 41.3% confidence. If yours predicted a cat: great! But how does it do on other images? Try a few more changing the `sample_idx` below.\n",
        "\n",
        "## Question 7. What is/are the main reason(s) for our SimpleNet and CustomNet to not work so well in this case, given that CIFAR-10 has both `dog` and `cat` labels?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9kX2ePwL73T"
      },
      "outputs": [],
      "source": [
        "def get_prediction(img, model, preprocess=None, class_names=None):\n",
        "    batch = preprocess(img) if preprocess is not None else img\n",
        "    batch = batch.unsqueeze(0)\n",
        "    batch = to_device(batch)\n",
        "    prediction = model(batch).squeeze(0).softmax(0)\n",
        "    class_id = prediction.argmax().item()\n",
        "    score = prediction[class_id].item()\n",
        "    category_name = class_names[class_id] if class_names is not None else class_id\n",
        "    return category_name, score\n",
        "\n",
        "sample_idx = 0\n",
        "img = train_data[sample_idx][0]\n",
        "img = img.resize((32, 32))\n",
        "category_name, score = get_prediction(\n",
        "    img, model_simple, cifar_train.transforms.transform, cifar_train.classes)\n",
        "print(f\"{category_name}: {100 * score:.1f}%\")\n",
        "img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21PSusBg366_"
      },
      "source": [
        "## Fine tuning\n",
        "\n",
        "Fine-tuning is the process of taking a strong pre-trained model and adapting it to a new dataset by training it further. Our pre-trained model is a 50-layer ResNet architecture, trained on the large ImageNet dataset to distinguish between 1000 classes.\n",
        "\n",
        "Fine-tuning involves freezing the weights of the lower layers in the pre-trained model, which are responsible for low-level features such as edges and textures, and training the upper layers on the new dataset. The weights in the upper layers are initialized randomly and then updated through backpropagation during training.\n",
        "\n",
        "We want to leverage the features of the ResNet and consider an extreme case, when all the layers are frozen, except for the last linear (fully connected) layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvn6UJeP36Sq"
      },
      "outputs": [],
      "source": [
        "# Imagenet accuracy: 80.858%\n",
        "weights=ResNet50_Weights.DEFAULT\n",
        "model_resnet = resnet50(weights=weights)\n",
        "model_resnet = to_device(model_resnet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnEz-TQLRCtw"
      },
      "source": [
        "ImageNet doesn't have a simple `cat` class: it rather has several classes such as `Egyptian cat`, `tabby cat`, etc. Assigning a cat to a wrong breed is considered the same as assigning a completely unrelated label. For example `sample_idx=3` is assigned to a `lynx` label (reasonable?), while `sample_idx=40` is assigned a `chihuahua` label as cats don't fall under the ImageNet specific breeds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3nubH2Jmur7"
      },
      "outputs": [],
      "source": [
        "sample_idx = 3\n",
        "img = train_data[sample_idx][0]\n",
        "category_name, score = get_prediction(img, model_resnet, weights.transforms(),\n",
        "                                      weights.meta[\"categories\"])\n",
        "print(f\"{category_name}: {100 * score:.1f}%\")\n",
        "img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH1JYyD7TVhp"
      },
      "source": [
        "## TODO #3: Fine-tune the ResNet\n",
        "\n",
        "Let's fine-tune the pre-trained ResNet. This involves the following steps:\n",
        "1. freeze the pretrained layers;\n",
        "2. modify the output to match the Dogs-vs-Cats class: you can simply change the `model_resnet.fc` output layer: there's no need to write new classes (e.g. if you wanted the last layer to be a convolution, you could re-define it as `model_resnet.fc = nn.Conv2D(3, 4, 5)`);\n",
        "3. run `train_and_test` with appropriate arguments.\n",
        "\n",
        "Can you achieve high accuracy now? Discuss your ResNet results (can be a part of your answer to Question 7)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a31YSFcULnBh"
      },
      "outputs": [],
      "source": [
        "# Dogs-vs-Cats train and test sets\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "catsdogs_train = ImageFolder(\"/tmp/cats_and_dogs_filtered/train\", transform=train_transforms)\n",
        "catsdogs_test = ImageFolder(\"/tmp/cats_and_dogs_filtered/validation\", transform=test_transforms)\n",
        "\n",
        "# Freeze the parameters\n",
        "for param in model_resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "###################################################\n",
        "# TODO: write your code here\n",
        "# Modify the ResNet, and fine-tune to Dogs-vs-Cats\n",
        "###################################################\n",
        "\n",
        "assert False, \"Modify the last layer of ResNet and fine-tune!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkwOQydi1iNw"
      },
      "source": [
        "## 4. Beyond image classification\n",
        "\n",
        "So far we looked only at the image classification task, which seems like a very narrow (and easy?) problem. But in fact, image classification networks are used as a core (backbone) for most of the image recognition problems.\n",
        "\n",
        "Our fine-tuned network distinguishes cats from dogs, but it also gives us its prediction confidence. Let's try to use this confidence to add (some) localization capabilities to the network.\n",
        "\n",
        "Object localization, or object detection involves modifying the network architecture to output both a class label for the input image and a bounding box that specifies the location of the object in the image. We won't build a complete detector, but we will make a step towards creating a region proposal network that says how likely a selected region contains an object of interest.\n",
        "\n",
        "Imagine that you know the size of the object you are looking for. For instance, in the image below, assume you know that you look for objects that occupy about 3% of the image that fit into a square of size $K \\times K$. For the image below, that would mean that the square has a side of $K = 170$ pixels. Let's see what confidence our network has for a random patch of size $K \\times K$ and for a patch that is centered on the dog.\n",
        "\n",
        "This may sound counterintuitive from the first glance that this process has any meaning. Our network can only predict `cat` or `dog` class, and we are asking it to classify a patch of the sky or forest! However, the fact that the network doesn't see any cat or dog features in the patch will hopefully push it towards predicting the corresponding class with a lower confidence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUkSGfmp1mQi"
      },
      "outputs": [],
      "source": [
        "# Load a high rest image containing a dog and display it.\n",
        "!wget https://www.blossomsfield.co.uk/wp-content/uploads/2020/10/WhatsApp-Image-2020-10-06-at-12.43.20.jpeg \\\n",
        "      -O /tmp/localize.jpeg\n",
        "img = Image.open(\"/tmp/localize.jpeg\")\n",
        "width, height = img.size\n",
        "width, height = 800, int(height * 800 / width)\n",
        "img = img.resize((width, height))\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Running our fine-tuned ResNet on a background patch.\n",
        "left = 35\n",
        "upper = 740\n",
        "size = 170\n",
        "box_random = (left, upper, left + size, upper + size)\n",
        "crop_random = img.crop(box_random)\n",
        "category_name_random, score_random = get_prediction(\n",
        "    crop_random, model_resnet, test_transforms, catsdogs_test.classes)\n",
        "print(f\"{category_name_random}: {100 * score_random:.1f}%\")\n",
        "crop_random"
      ],
      "metadata": {
        "id": "DnW4sDD6ZVMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running our fine-tuned ResNet on a dog patch.\n",
        "left = 290\n",
        "upper = 520\n",
        "size = 170\n",
        "box_center = (left, upper, left + size, upper + size)\n",
        "crop_center = img.crop(box_center)\n",
        "category_name_center, score_center = get_prediction(\n",
        "    crop_center, model_resnet, test_transforms, catsdogs_test.classes)\n",
        "print(f\"{category_name_center}: {100 * score_center:.1f}%\")\n",
        "crop_center"
      ],
      "metadata": {
        "id": "-qQn5l2wbdyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the function below to draw a set of patches on top of the image."
      ],
      "metadata": {
        "id": "ozPIihxfjIdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw(boxes, scores, color=(255, 0, 0)):\n",
        "    width, height = img.size\n",
        "    nboxes = len(boxes)\n",
        "    pad = 10\n",
        "    im2show = img.copy()\n",
        "    img_draw = ImageDraw.Draw(im2show)\n",
        "    for i, box in enumerate(boxes):\n",
        "        score = scores[i]\n",
        "        img_draw.rectangle(box, outline=color, width=5)\n",
        "\n",
        "    return im2show\n",
        "\n",
        "boxes = [box_center, box_random]\n",
        "names = [category_name_center, category_name_random]\n",
        "scores = [score_center, score_random]\n",
        "im2show = draw(boxes, scores, color=\"blue\")\n",
        "im2show"
      ],
      "metadata": {
        "id": "LCdrMD0QLTlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO #4: Implement the sliding window and visualize the most and the least confident predictions\n",
        "\n",
        "Let's produce a set of candidates in a sliding window fashion. That is, place a window of size $K \\times K$ into the top left corner, and evaluate the score of the corresponding crop to contain class `dog`. Now slide this window across all possible locations with step $s$ (i.e. evaluate a crop of size $K \\times K$ with the top left corner coordinate $(0, s)$ next). Record all window positions and the corresponding scores for the `dog` class. Then sort them and plot top-20 and bottom-20 scoring ones. Pick $s$ yourself, and $K = 170$."
      ],
      "metadata": {
        "id": "RnOyOskNI4cq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###################################################\n",
        "# TODO: write your code here\n",
        "# Implement the sliding window approach.\n",
        "###################################################\n",
        "\n"
      ],
      "metadata": {
        "id": "C2NKN6lXb2WJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the top-20 scoring boxes\n",
        "high_scoring_img = draw(boxes[:20], scores[:20], color=\"green\")\n",
        "high_scoring_img"
      ],
      "metadata": {
        "id": "mxfh0dxoUj8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the bottom-20 scoring boxes\n",
        "low_scoring_img = draw(boxes[-20:], scores[-20:], color=\"red\")\n",
        "low_scoring_img"
      ],
      "metadata": {
        "id": "MTUpLZyxR4W0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discuss your results: where did the top-20 scoring boxes land? How about the bottom-20 ones? Do any of the low scoring boxes still contain any pixels belonging to the dog? Why might that be (i.e. why a set of pixels belonging to the dog may score lower than a corner box with just the sky or just the grass)? Answer this final question as well in your report:\n",
        "\n",
        "## Question 8. What drawbacks does such an approach of creating region proposals have? What extra steps do you need to make to create a real detector?\n"
      ],
      "metadata": {
        "id": "scziJ04jmJ0k"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}